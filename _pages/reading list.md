---
layout: single
title: "Paper Reading"
permalink: /reading list/
author_profile: true
---

## AI Chip/Accelerator
* ISSCC
  - A 1.42TOPS/W Deep Convolutional Neural Network Recognition Processor for Intelligent IoE Systems(2016)
  - A 288μW Programmable Deep-Learning Processor with 270KB On-Chip Weight Storage Using Non-Uniform Memory Hierarchy for Mobile Intelligence(2017)
  - A 0.62mW Ultra-Low-Power Convolutional-NeuralNetwork Face-Recognition Processor and a CIS Integrated with Always-On Haar-Like Face Detector(2017)
  - A 2.9TOPS/W Deep Convolutional Neural Network SoC in FD-SOI 28nm for Intelligent Embedded Systems(2017)
  - DNPU: An 8.1TOPS/W Reconfigurable CNN-RNN Processor for General-Purpose Deep Neural Networks(2017)
  - UNPU: A 50.6TOPS/W Unified Deep Neural Network Accelerator with 1b-to-16b Fully-Variable Weight Bit-Precision(2018)
  - An 89TOPS/W and 16.3TOPS/mm2 All-Digital SRAM-Based Full-Precision Compute-In-Memory Macro in 22nm for Machine-Learning Edge Applications(2021)
* JSSC
  - Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks(2017)
  - A High Energy Efficient Reconfigurable Hybrid Neural Network Processor for Deep Learning Applications(2018)
  - TranCIM: Full-Digital Bitline-Transpose CIM-based Sparse Transformer Accelerator With Pipeline/Parallel Reconfigurable Modes(2023)
* VLSI
  - Deep Convolutional Neural Network Architecture With Reconfigurable Computation Patterns(2017)
  - A 40nm Analog-Input ADC-Free Compute-in-Memory RRAM Macro with Pulse-Width Modulation between Sub-arrays(2022)
* ISCA
  - In-Datacenter Performance Analysis of a Tensor Processing Unit(2017)
  - SCALEDEEP:A Scalable Compute Architecture for Learning and Evaluating Deep Networks(2017)
  - SCNN: An Accelerator for Compressed-sparse Convolutional Neural Networks(2017)
  - ELSA: Hardware-Software Co-design for Efficient, Lightweight Self-Attention Mechanism in Neural Networks(2021)
* HPCA
  - A3: Accelerating Attention Mechanisms in Neural Networks with Approximation(2020)
* TCAS-I
  - ENNA: An Efficient Neural Network Accelerator Design Based on ADC-Free Compute-In-Memory Subarrays(2023)
* MWSCAS
  - 8T XNOR-SRAM based Parallel Compute-in-Memory for Deep Neural Network Accelerator(2020)
* Others
  - Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks(2016)
  - Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1(2016)
  - Efficient Processing of Deep Neural Networks: A Tutorial and Survey(2017)
  - FINN: A Framework for Fast, Scalable Binarized Neural Network Inference(2017)
  - A Lightweight YOLOv2: A Binarized CNN with A Parallel Support Vector Regression for an FPGA(2018)
  - Eyeriss v2: A Flexible Accelerator for Emerging Deep Neural Networks on Mobile Devices(2019)
  - Compute-in-Memory Chips for Deep Learning: Recent Trends and Prospects(2021)
  - Digital Versus Analog Artificial Intelligence Accelerators: Advances, trends, and emerging designs(2022)
  - ULECGNet: An Ultra-Lightweight End-to-End ECG Classification Neural Network(2022)

## Machine Learning
  - Attention Is All You Need(2017)
  - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding(2019)
  - Q8BERT: Quantized 8Bit BERT(2019)
  - Language Models are Few-Shot Learners(2020)
